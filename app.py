import streamlit as st
import os
import tempfile
import requests
import json
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Tuple
import time
import hashlib
from datetime import datetime
import re

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import google.generativeai as genai
    from PyPDF2 import PdfReader
    from docx import Document
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    import pandas as pd
    import numpy as np
    LIBS_AVAILABLE = True
except ImportError as e:
    st.error(f"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í•„ìš”: {e}")
    LIBS_AVAILABLE = False

# í˜ì´ì§€ ì„¤ì • (ë‹¤í¬ëª¨ë“œ ê°•í™”)
st.set_page_config(
    page_title="AHN'S Advanced RAG Assistant",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë‹¤í¬ëª¨ë“œ CSS (Streamlit Cloud í˜¸í™˜)
st.markdown("""
<style>
    .stApp {
        background: linear-gradient(135deg, #1e1e2e 0%, #2a2a3e 100%);
        color: #ffffff;
    }
    
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(0,0,0,0.3);
    }
    
    .main-title {
        font-size: 2.5em;
        font-weight: bold;
        color: #ffffff;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.5);
        margin: 0;
    }
    
    .main-subtitle {
        font-size: 1.2em;
        color: #e0e0e0;
        margin-top: 0.5rem;
    }
    
    .chat-container {
        background: rgba(255,255,255,0.05);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255,255,255,0.1);
    }
    
    .user-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 15px;
        margin: 0.5rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.2);
    }
    
    .assistant-message {
        background: rgba(255,255,255,0.1);
        color: #ffffff;
        padding: 1rem;
        border-radius: 15px;
        margin: 0.5rem 0;
        border-left: 4px solid #667eea;
    }
    
    .status-box {
        background: rgba(102, 126, 234, 0.2);
        border: 1px solid #667eea;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    .metric-card {
        background: rgba(255,255,255,0.1);
        border-radius: 10px;
        padding: 1rem;
        text-align: center;
        margin: 0.5rem;
        border: 1px solid rgba(255,255,255,0.2);
    }
    
    /* Streamlit ì»´í¬ë„ŒíŠ¸ ìŠ¤íƒ€ì¼ë§ */
    .stTextInput > div > div > input {
        background-color: rgba(255,255,255,0.1);
        color: #ffffff;
        border: 1px solid rgba(255,255,255,0.3);
        border-radius: 10px;
    }
    
    .stSelectbox > div > div > select {
        background-color: rgba(255,255,255,0.1);
        color: #ffffff;
        border: 1px solid rgba(255,255,255,0.3);
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.5rem 1rem;
        font-weight: bold;
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(102, 126, 234, 0.4);
    }
    
    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ë§ */
    .css-1d391kg, .css-1lcbmhc {
        background-color: rgba(30, 30, 46, 0.95);
    }
    
    .sidebar-content {
        color: #ffffff;
    }
</style>
""", unsafe_allow_html=True)

# ë©”ì¸ í—¤ë”
st.markdown("""
<div class="main-header">
    <h1 class="main-title">ğŸ›¡ï¸ AHN'S Advanced RAG Assistant</h1>
    <p class="main-subtitle">ì§€ëŠ¥í˜• ë¬¸ì„œ ë¶„ì„ ë° ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ</p>
</div>
""", unsafe_allow_html=True)

class AdvancedRAGSystem:
    def __init__(self):
        """ê³ ê¸‰ RAG ì‹œìŠ¤í…œ (ì•ˆì „í•œ ì´ˆê¸°í™”)"""
        self.documents = []
        self.chunks = []
        self.embeddings = []
        self.is_fitted = False
        self.embedding_model = None
        
        # SentenceTransformer ëª¨ë¸ ì•ˆì „í•˜ê²Œ ë¡œë“œ
        try:
            with st.spinner('ğŸ¤– AI ëª¨ë¸ ë¡œë”© ì¤‘...'):
                self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            st.success('âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!')
        except Exception as e:
            st.error(f"âŒ SentenceTransformer ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.info("ğŸ’¡ TF-IDF ë°±ì—… ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            # TF-IDF ë°±ì—… ëª¨ë“œ
            from sklearn.feature_extraction.text import TfidfVectorizer
            self.tfidf_vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))
            self.use_tfidf_backup = True
        else:
            self.use_tfidf_backup = False
        
    def add_document(self, content: str, metadata: dict = None):
        """ë¬¸ì„œ ì¶”ê°€"""
        doc_id = len(self.documents)
        self.documents.append({
            'id': doc_id,
            'content': content,
            'metadata': metadata or {}
        })
        
        # ì²­í‚¹
        chunks = self.chunk_text(content, chunk_size=500, overlap=100)
        for i, chunk in enumerate(chunks):
            self.chunks.append({
                'doc_id': doc_id,
                'chunk_id': f"{doc_id}_{i}",
                'content': chunk,
                'metadata': metadata or {}
            })
    
    def chunk_text(self, text: str, chunk_size: int = 500, overlap: int = 100) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        if len(text) <= chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # ë¬¸ì¥ ê²½ê³„ì—ì„œ ìë¥´ê¸°
            if end < len(text):
                while end > start and text[end] not in '.!?\n':
                    end -= 1
                if end == start:
                    end = start + chunk_size
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            start = end - overlap
            if start >= len(text):
                break
                
        return chunks
    
    def fit_vectors(self):
        """ë²¡í„°í™” ìˆ˜í–‰ (ì•ˆì „í•œ ì²˜ë¦¬)"""
        if not self.chunks:
            return False
            
        try:
            chunk_texts = [chunk['content'] for chunk in self.chunks]
            
            if not self.use_tfidf_backup and self.embedding_model is not None:
                # SentenceTransformer ì‚¬ìš©
                self.embeddings = self.embedding_model.encode(chunk_texts)
            else:
                # TF-IDF ë°±ì—… ëª¨ë“œ
                self.embeddings = self.tfidf_vectorizer.fit_transform(chunk_texts)
            
            self.is_fitted = True
            return True
        except Exception as e:
            st.error(f"ë²¡í„°í™” ì˜¤ë¥˜: {e}")
            return False
    
    def hybrid_search(self, query: str, top_k: int = 3, alpha: float = 0.7) -> List[Dict]:
        """ê²€ìƒ‰ ìˆ˜í–‰ (ì•ˆì „í•œ ì²˜ë¦¬)"""
        if not self.is_fitted or not self.chunks:
            return []
        
        try:
            if not self.use_tfidf_backup and self.embedding_model is not None:
                # SentenceTransformer ì‚¬ìš©
                query_embedding = self.embedding_model.encode([query])
                similarities = cosine_similarity(query_embedding, self.embeddings).flatten()
            else:
                # TF-IDF ë°±ì—… ëª¨ë“œ
                query_vector = self.tfidf_vectorizer.transform([query])
                similarities = cosine_similarity(query_vector, self.embeddings).flatten()
            
            # ìƒìœ„ ê²°ê³¼ ì„ íƒ
            top_indices = np.argsort(similarities)[::-1][:top_k]
            
            results = []
            for idx in top_indices:
                if similarities[idx] > 0.1:  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
                    results.append({
                        'chunk': self.chunks[idx],
                        'score': float(similarities[idx]),
                        'content': self.chunks[idx]['content']
                    })
            
            return results
            
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return [])[::-1][:top_k]
            
            results = []
            for idx in top_indices:
                if similarities[idx] > 0.1:  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
                    results.append({
                        'chunk': self.chunks[idx],
                        'score': float(similarities[idx]),
                        'content': self.chunks[idx]['content']
                    })
            
            return results
            
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
def extract_text_from_pdf(file) -> str:
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        reader = PdfReader(file)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        st.error(f"PDF ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return ""

def extract_text_from_docx(file) -> str:
    """DOCXì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        doc = Document(file)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text
    except Exception as e:
        st.error(f"DOCX ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return ""

def extract_text_from_txt(file) -> str:
    """TXT íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        text = file.read().decode('utf-8')
        return text
    except Exception as e:
        st.error(f"TXT ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return ""

# Luxia API ì„¤ì •
LUXIA_API_KEY = "U2FsdGVkX19ZW0c+KOFb9zDy5eoyiz+I6icUKb2uOjuvUnzY1TaixWa5Ouy0s87vCdtqiQMmScIWcRbEJWcfXt/jS6RMWCW+38TU47bpj82JdafHt3ODi9VHfPmSrZJCMTwP4BJ471NZTqTLakFLpMQ/PTjafRebBJpfLSDeyBj4fX1VM+NnoH8u8aGG5AV4"

def get_luxia_response(prompt: str, context: str = "") -> str:
    """Luxia API í˜¸ì¶œ"""
    try:
        url = "https://api.luxia.one/api/luxia-chatbot-msg"
        headers = {
            "Content-Type": "application/json",
            "User-Agent": "Mozilla/5.0"
        }
        
        full_prompt = f"{context}\n\nì‚¬ìš©ì ì§ˆë¬¸: {prompt}" if context else prompt
        
        payload = {
            "message": full_prompt,
            "key": LUXIA_API_KEY
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            return result.get('message', 'ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        else:
            return f"API ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {response.status_code})"
            
    except Exception as e:
        return f"API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}"

def get_gemini_response(prompt: str, context: str = "") -> str:
    """Gemini API í˜¸ì¶œ (ë°±ì—…)"""
    try:
        genai.configure(api_key=st.secrets.get("GEMINI_API_KEY", ""))
        model = genai.GenerativeModel('gemini-pro')
        
        full_prompt = f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:\n\n{context}\n\nì§ˆë¬¸: {prompt}"
        
        response = model.generate_content(full_prompt)
        return response.text
        
    except Exception as e:
        return f"Gemini API ì˜¤ë¥˜: {str(e)}"

# ìë™ ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜
def load_default_document():
    """ê¸°ë³¸ ë¬¸ì„œ ìë™ ë¡œë“œ"""
    # ì‹¤ì œ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    if os.path.exists("pstorm_pw.docx"):
        try:
            with open("pstorm_pw.docx", "rb") as f:
                content = extract_text_from_docx(f)
                if content.strip():
                    return content, "pstorm_pw.docx"
        except Exception as e:
            st.warning(f"ê¸°ë³¸ ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # í•˜ë“œì½”ë”©ëœ ìƒ˜í”Œ ë¬¸ì„œ
    return """
# íšŒì‚¬ ë³´ì•ˆ ì •ì±… ë° ë¹„ë°€ë²ˆí˜¸ ê´€ë¦¬ ê°€ì´ë“œ

## 1. ë¹„ë°€ë²ˆí˜¸ ì •ì±…
- ìµœì†Œ 8ì ì´ìƒ, ì˜ë¬¸ ëŒ€ì†Œë¬¸ì, ìˆ«ì, íŠ¹ìˆ˜ë¬¸ì í¬í•¨
- 90ì¼ë§ˆë‹¤ ë³€ê²½ í•„ìˆ˜
- ì´ì „ 5ê°œ ë¹„ë°€ë²ˆí˜¸ ì¬ì‚¬ìš© ê¸ˆì§€
- ê°œì¸ì •ë³´ í¬í•¨ ê¸ˆì§€ (ìƒë…„ì›”ì¼, ì´ë¦„ ë“±)

## 2. ì‹œìŠ¤í…œ ì ‘ê·¼ ë³´ì•ˆ
- ì—…ë¬´ìš© ê³„ì •ê³¼ ê°œì¸ ê³„ì • ë¶„ë¦¬ ì‚¬ìš©
- ê³µìš© ì»´í“¨í„°ì—ì„œ ìë™ ë¡œê·¸ì¸ ì„¤ì • ê¸ˆì§€
- ì—…ë¬´ ì¢…ë£Œ ì‹œ ë°˜ë“œì‹œ í™”ë©´ ì ê¸ˆ
- USB ë“± ì™¸ë¶€ ì €ì¥ë§¤ì²´ ì‚¬ìš© ì‹œ ë³´ì•ˆ ìŠ¹ì¸ í•„ìš”

## 3. VPN ë° ì›ê²© ì ‘ì†
- ì¬íƒê·¼ë¬´ ì‹œ íšŒì‚¬ ìŠ¹ì¸ VPNë§Œ ì‚¬ìš©
- ê³µìš© Wi-Fiì—ì„œ ì—…ë¬´ ì‹œìŠ¤í…œ ì ‘ì† ê¸ˆì§€
- VPN ì—°ê²° ì‹œ ê°œì¸ìš© í”„ë¡œê·¸ë¨ ë™ì‹œ ì‚¬ìš© ì œí•œ

## 4. ë°ì´í„° ë³´í˜¸
- íšŒì‚¬ ê¸°ë°€ ì •ë³´ ê°œì¸ ì €ì¥ì†Œ ë³´ê´€ ê¸ˆì§€
- í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì´ìš© ì‹œ ITíŒ€ ìŠ¹ì¸ í•„ìš”
- ì •ê¸° ë°±ì—… ìˆ˜í–‰ ë° ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì‹¤ì‹œ

## 5. ë³´ì•ˆ ì‚¬ê³  ëŒ€ì‘
- ë³´ì•ˆ ì‚¬ê³  ë°œê²¬ ì‹œ ì¦‰ì‹œ ITë³´ì•ˆíŒ€ ì‹ ê³  (ë‚´ì„ : 1588)
- ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë©”ì¼ ìˆ˜ì‹  ì‹œ ì²¨ë¶€íŒŒì¼ ì‹¤í–‰ ê¸ˆì§€
- ê°œì¸ì •ë³´ ìœ ì¶œ ì˜ì‹¬ ì‹œ ê°œì¸ì •ë³´ë³´í˜¸íŒ€ ì—°ë½ (ë‚´ì„ : 1577)

## 6. êµìœ¡ ë° ì ê²€
- ë¶„ê¸°ë³„ ë³´ì•ˆ êµìœ¡ ì´ìˆ˜ ì˜ë¬´
- ì›” 1íšŒ ë³´ì•ˆ ì ê²€ ì‹¤ì‹œ
- ë³´ì•ˆ ìœ„ë°˜ ì‹œ ê²½ê³  ì¡°ì¹˜ ë° ì¬êµìœ¡

## ì—°ë½ì²˜
- ITë³´ì•ˆíŒ€: 1588
- ê°œì¸ì •ë³´ë³´í˜¸íŒ€: 1577
- ì´ë¬´íŒ€: 1500
""", "ê¸°ë³¸_ë³´ì•ˆì •ì±….txt"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'rag_system' not in st.session_state:
        st.session_state.rag_system = AdvancedRAGSystem()
        
        # ê¸°ë³¸ ë¬¸ì„œ ìë™ ë¡œë“œ
        default_content, filename = load_default_document()
        st.session_state.rag_system.add_document(
            default_content, 
            {'filename': filename, 'upload_time': datetime.now()}
        )
        st.session_state.rag_system.fit_vectors()
        
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'processed_files' not in st.session_state:
        st.session_state.processed_files = []

# ë©”ì¸ í•¨ìˆ˜
def main():
    if not LIBS_AVAILABLE:
        st.error("í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. requirements.txtë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    initialize_session_state()
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.markdown('<div class="sidebar-content">', unsafe_allow_html=True)
        
        st.markdown("### âš™ï¸ ì„¤ì •")
        
        # AI ëª¨ë¸ ì„ íƒ
        ai_model = st.selectbox(
            "ğŸ§  AI ëª¨ë¸ ì„ íƒ",
            ["Luxia", "Gemini"],
            index=0,
            help="ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        # API í‚¤ ì„¤ì •
        st.markdown("### ğŸ”‘ Luxia API í‚¤")
        luxia_key_display = "â€¢" * 20 + LUXIA_API_KEY[-10:] if len(LUXIA_API_KEY) > 10 else "â€¢" * 10
        st.text_input("API í‚¤", value=luxia_key_display, disabled=True, type="password")
        
        st.markdown("### ğŸ” ê²€ìƒ‰ ì„¤ì •")
        
        # ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜
        retrieval_count = st.slider(
            "ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜",
            min_value=1,
            max_value=10,
            value=5,
            help="ê²€ìƒ‰ ì‹œ ì°¸ê³ í•  ë¬¸ì„œ ì²­í¬ ê°œìˆ˜"
        )
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
        alpha = st.slider(
            "í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜",
            min_value=0.00,
            max_value=1.00,
            value=0.70,
            step=0.05,
            help="ì˜ë¯¸ì  ê²€ìƒ‰ê³¼ í‚¤ì›Œë“œ ê²€ìƒ‰ì˜ ë¹„ìœ¨ ì¡°ì •"
        )
        
        st.markdown("### ğŸ“„ ë¬¸ì„œ ì—…ë¡œë“œ")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_files = st.file_uploader(
            "ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['pdf', 'docx', 'txt'],
            accept_multiple_files=True,
            help="PDF, DOCX, TXT íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        
        # íŒŒì¼ ì²˜ë¦¬
        if uploaded_files:
            for uploaded_file in uploaded_files:
                if uploaded_file.name not in [f['name'] for f in st.session_state.processed_files]:
                    with st.spinner(f'{uploaded_file.name} ì²˜ë¦¬ ì¤‘...'):
                        content = ""
                        
                        if uploaded_file.type == "application/pdf":
                            content = extract_text_from_pdf(uploaded_file)
                        elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                            content = extract_text_from_docx(uploaded_file)
                        elif uploaded_file.type == "text/plain":
                            content = extract_text_from_txt(uploaded_file)
                        
                        if content.strip():
                            st.session_state.rag_system.add_document(
                                content,
                                {
                                    'filename': uploaded_file.name,
                                    'upload_time': datetime.now(),
                                    'size': len(content)
                                }
                            )
                            st.session_state.rag_system.fit_vectors()
                            st.session_state.processed_files.append({
                                'name': uploaded_file.name,
                                'size': len(content),
                                'time': datetime.now()
                            })
                            st.success(f'{uploaded_file.name} ì²˜ë¦¬ ì™„ë£Œ!')
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        
        # ìƒíƒœ ì •ë³´
        total_docs = len(st.session_state.rag_system.documents)
        total_chunks = len(st.session_state.rag_system.chunks)
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"""
            <div class="metric-card">
                <div style="font-size: 1.5em;">ğŸ“š</div>
                <div style="font-size: 1.2em; font-weight: bold;">{total_docs}</div>
                <div style="font-size: 0.9em;">ë¡œë“œëœ ë¬¸ì„œ</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="metric-card">
                <div style="font-size: 1.5em;">ğŸ”</div>
                <div style="font-size: 1.2em; font-weight: bold;">{total_chunks}</div>
                <div style="font-size: 0.9em;">ì²­í¬</div>
            </div>
            """, unsafe_allow_html=True)
        
        # ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì •ë³´
        st.markdown(f"""
        <div class="status-box">
            <strong>ğŸ§  ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸:</strong><br>
            {ai_model}
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # ë©”ì¸ ì½˜í…ì¸  ì˜ì—­
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    
    # ì§ˆë¬¸ ì…ë ¥
    user_input = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="ì˜ˆ: ë¹„ë°€ë²ˆí˜¸ ì •ì±…ì´ ë¬´ì—‡ì¸ê°€ìš”?",
        key="user_question"
    )
    
    col1, col2 = st.columns([1, 5])
    with col1:
        ask_button = st.button("ğŸ” ì§ˆë¬¸", type="primary", use_container_width=True)
    
    if ask_button and user_input:
        with st.spinner('ë‹µë³€ ìƒì„± ì¤‘...'):
            # ê²€ìƒ‰ ìˆ˜í–‰
            search_results = st.session_state.rag_system.hybrid_search(
                user_input,
                top_k=retrieval_count,
                alpha=alpha
            )
            
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = ""
            if search_results:
                context = "ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©:\n\n"
                for i, result in enumerate(search_results, 1):
                    context += f"[ë¬¸ì„œ {i}]\n{result['content']}\n\n"
            
            # AI ì‘ë‹µ ìƒì„±
            if ai_model == "Luxia":
                response = get_luxia_response(user_input, context)
            else:
                response = get_gemini_response(user_input, context)
            
            # ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
            st.session_state.chat_history.append({
                'user': user_input,
                'assistant': response,
                'timestamp': datetime.now(),
                'search_results': search_results
            })
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for chat in reversed(st.session_state.chat_history):
        st.markdown(f"""
        <div class="user-message">
            <strong>ğŸ‘¤ ì§ˆë¬¸:</strong> {chat['user']}
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
        <div class="assistant-message">
            <strong>ğŸ¤– ë‹µë³€:</strong><br>
            {chat['assistant']}
        </div>
        """, unsafe_allow_html=True)
        
        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        if chat.get('search_results'):
            with st.expander(f"ğŸ“‹ ì°¸ê³  ë¬¸ì„œ ({len(chat['search_results'])}ê°œ)"):
                for i, result in enumerate(chat['search_results'], 1):
                    st.markdown(f"""
                    **ë¬¸ì„œ {i}** (ìœ ì‚¬ë„: {result['score']:.3f})
                    
                    {result['content'][:300]}...
                    """)
        
        st.markdown("---")
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡
    if st.session_state.processed_files:
        st.markdown("### ğŸ“ ì—…ë¡œë“œëœ íŒŒì¼")
        for file_info in st.session_state.processed_files:
            st.markdown(f"""
            <div class="status-box">
                ğŸ“„ **{file_info['name']}**<br>
                í¬ê¸°: {file_info['size']:,} ê¸€ì | 
                ì—…ë¡œë“œ: {file_info['time'].strftime('%Y-%m-%d %H:%M')}
            </div>
            """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()